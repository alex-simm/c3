{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 13:30:26.578193: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-18 13:30:26.578238: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Libs and helpers\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import tensorflow as tf\n",
    "\n",
    "import c3.libraries.algorithms as algorithms\n",
    "import c3.libraries.envelopes\n",
    "import c3.libraries.fidelities as fidelities\n",
    "import c3.utils.qt_utils as qt_utils\n",
    "from c3.signal.pulse import EnvelopeDrag\n",
    "from c3.utils.tf_utils import tf_project_to_comp, tf_abs, tf_unitary_overlap\n",
    "import four_level_transmons.custom_gates as custom_gates\n",
    "from c3.experiment import Experiment as Exp\n",
    "# Main C3 objects\n",
    "from c3.libraries import constants\n",
    "from c3.model import Model as Mdl\n",
    "from c3.optimizers.optimalcontrol import OptimalControl\n",
    "from c3.parametermap import ParameterMap as PMap\n",
    "from four_level_transmons.DataOutput import DataOutput\n",
    "from four_level_transmons.custom_envelopes import *\n",
    "from four_level_transmons.plotting import *\n",
    "from four_level_transmons.utilities import *\n",
    "from four_level_transmons.blackbox import generateSignalFromConfig\n",
    "tf.config.run_functions_eagerly(True)\n",
    "np.set_printoptions(linewidth=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== WARNING: no output directory specified ============\n"
     ]
    }
   ],
   "source": [
    "if len(sys.argv[1:]) > 0 and \"ipykernel_launcher\" not in sys.argv[0]:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"output\", help=\"Output directory\")\n",
    "    args = parser.parse_args()\n",
    "    output_dir = args.output\n",
    "    print(\"Output directory: \", output_dir)\n",
    "else:\n",
    "    print(\"=========== WARNING: no output directory specified ============\")\n",
    "    output_dir = \"./output\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# general settings\n",
    "numPWCPieces = 60\n",
    "usePWC = True\n",
    "useDRAG = False\n",
    "t_final = 500e-9\n",
    "sim_res = 50e9\n",
    "awg_res = numPWCPieces / t_final if usePWC else 2e9\n",
    "isDressed = True\n",
    "\n",
    "ALGORITHM_LBFGS = 0\n",
    "ALGORITHM_LBFGS_GRAD_FREE = 1\n",
    "ALGORITHM_CMAES = 2\n",
    "ALGORITHM_GCMAES = 3\n",
    "selected_algorithms = [ALGORITHM_LBFGS]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "entanglementInitState = [0, 1]\n",
    "entanglementInitStateFull = [0, 1]\n",
    "\n",
    "def printSignal(exper: Experiment, qubits: List[chip.Qubit],\n",
    "                gate: gates.Instruction, output: DataOutput,\n",
    "                states: List[Tuple[float, str]] = None):\n",
    "    signals = exper.pmap.generator.generate_signals(gate)\n",
    "    for i, qubit in enumerate(qubits):\n",
    "        # generate signal\n",
    "        drive = getDrive(exper.pmap.model, qubit).name\n",
    "        signal = signals[drive]\n",
    "        ts = signal[\"ts\"].numpy()\n",
    "        values = signal[\"values\"].numpy()\n",
    "\n",
    "        # save data\n",
    "        peakFrequencies, peakValues = findFrequencyPeaks(ts, values, 25, normalise=True)\n",
    "        sortIndices = np.argsort(peakValues)\n",
    "        print(f\"peaks: {drive}\")\n",
    "        for idx in sortIndices:\n",
    "            print(f\"\\t{peakFrequencies[idx]:e} (amp={peakValues[idx]:e})\")\n",
    "        output.save([ts, values], f\"signal_t{i + 1}\")\n",
    "\n",
    "        # plot\n",
    "        plotSignalAndSpectrum(ts, real=values, filename=output.createFileName(f\"signal_t{i + 1}\", \"svg\"),\n",
    "                              spectralThreshold=None)\n",
    "        plotSignalAndSpectrum(ts, real=values, filename=output.createFileName(f\"signal_detail_t{i + 1}\", \"svg\"),\n",
    "                              spectralThreshold=1e-4)\n",
    "        plotSignalAndSpectrum(ts, real=values, filename=output.createFileName(f\"signal_detail_with_states_t{i + 1}\", \"svg\"),\n",
    "                              states=states,\n",
    "                              spectralThreshold=1e-4, spectralCutoff=(20e6, 700e6))\n",
    "\n",
    "\n",
    "def printTimeEvolution(exper: Experiment, init: tf.Tensor, gate: gates.Instruction,\n",
    "                       labels: List[str], output: DataOutput):\n",
    "    populations = calculatePopulation(exper, init, [gate.get_key()])\n",
    "    output.save(populations, \"population\")\n",
    "    plotPopulation(exper, populations, sequence=[gate.get_key()],\n",
    "                   labels=labels, filename=output.createFileName(\"population\", \"svg\"))\n",
    "    plotSplittedPopulation(exper, populations, [gate.get_key()], filename=output.createFileName(\"population\", \"svg\"))\n",
    "\n",
    "\n",
    "def stateEntropyAB(state: tf.Tensor):\n",
    "    rho = densityMatrix(state)\n",
    "    if state.shape[0] > 16:\n",
    "        rho = tf_project_to_comp(rho, dims=qubit_levels, outdims=[4, 4])\n",
    "    rhoBD = tf_project_to_comp(rho, dims=[2, 2, 2, 2], outdims=[0, 2, 0, 2])\n",
    "    #rhoBD = partialTrace(rho, [1, 3])\n",
    "    rhoB = partialTrace(rhoBD, [0])\n",
    "    #rhoAB = partialTrace(rho, [0, 1])\n",
    "    return entanglementEntropy(rhoB)  #- entanglementEntropy(rhoBD)\n",
    "\n",
    "\n",
    "def printEntanglementEvolution(exper: Experiment, gate: gates.Instruction, output: DataOutput):\n",
    "    entropies = []\n",
    "    #for state in [(0, 1), (0, 5), (1, 6), (5, 6)]:\n",
    "    for state in [(0, 1), (0, 4), (1, 5), (4, 5)]:\n",
    "    #for state in [(0, 4), (5, 6), (10, 11), (12, 13)]:\n",
    "        psi_init = np.zeros(shape=(model.tot_dim,))\n",
    "        psi_init[state[0]] = psi_init[state[1]] = 1 / np.sqrt(2)\n",
    "        entropy = calculateObservable(exper, np.array(psi_init), [gate.get_key()], stateEntropyAB)\n",
    "        entropies.append(entropy)\n",
    "    entropies = np.array(entropies)\n",
    "    plotPopulation(exper, entropies, sequence=[gate.get_key()],\n",
    "                   labels=[\"00+01\", \"00+10\", \"01+11\", \"10+11\"],\n",
    "                   filename=output.createFileName(\"entanglement\", \"svg\"),\n",
    "                   labelY=\"Entropy\")\n",
    "\n",
    "\n",
    "def printMatrix(M: np.array, labels: List[str], name: str, output: DataOutput):\n",
    "    #plotComplexMatrix(M, xlabels=labels, ylabels=labels, filename=output.createFileName(name))\n",
    "    plotComplexMatrixHinton(M, maxAbsolute=1, xlabels=labels, ylabels=labels, gridColour=\"gray\",\n",
    "                            filename=output.createFileName(name, \"svg\"), colourMap='hsv')\n",
    "    #plotComplexMatrixAbsOrPhase(M, xlabels=labels, ylabels=labels, phase=True,\n",
    "    #                            filename=output.createFileName(name + \"_phase\"))\n",
    "    #plotComplexMatrixAbsOrPhase(M, xlabels=labels, ylabels=labels, phase=False,\n",
    "    #                            filename=output.createFileName(name + \"_abs\"))\n",
    "\n",
    "\n",
    "def printPropagator(exper: Experiment, gate: gates.Instruction,\n",
    "                    labels: List[str], output: DataOutput,\n",
    "                    savePartials=False):\n",
    "    U = exper.propagators[gate.get_key()]\n",
    "    output.save(U, \"propagator\")\n",
    "    #output.save(exper.partial_propagators[gate.get_key()], \"partial_propagators\")\n",
    "    #os.system('bzip2 -9 \"' + output.createFileName('partial_propagators.npy') + '\"')\n",
    "    printMatrix(U, labels, \"propagator\", output)\n",
    "    if savePartials:\n",
    "        output.save(exper.partial_propagators[gate.get_key()], \"partial_propagators\")\n",
    "\n",
    "\n",
    "def printAllSignals(exper: Experiment, qubit: chip.Qubit, output: DataOutput, directory: str):\n",
    "    try:\n",
    "        os.mkdir(output.getDirectory() + \"/\" + directory)\n",
    "    except:\n",
    "        pass\n",
    "    drive = getDrive(exper.pmap.model, qubit)\n",
    "    outputs = exper.pmap.generator.global_signal_stack[drive.name]\n",
    "    for name, values in outputs.items():\n",
    "        filename = output.createFileName(directory + \"/device_\" + name, \"svg\")\n",
    "        time = values[\"ts\"].numpy()\n",
    "        if name.startswith(\"LO\"):\n",
    "            #time = time[:100]\n",
    "            re = values[\"inphase\"].numpy()\n",
    "            im = values[\"quadrature\"].numpy()\n",
    "            plotSignalAndSpectrum(time, real=re, min_signal_limit=None,\n",
    "                                  spectralThreshold=5e-4,\n",
    "                                  filename=output.createFileName(directory + \"/device_\" + name + \"_real\", \"svg\"))\n",
    "            plotSignalAndSpectrum(time, real=im, min_signal_limit=None,\n",
    "                                  spectralThreshold=5e-4,\n",
    "                                  filename=output.createFileName(directory + \"/device_\" + name + \"_imag\", \"svg\"))\n",
    "        elif \"values\" in values:\n",
    "            signal = values[\"values\"].numpy()\n",
    "            plotSignalAndSpectrum(time, signal, min_signal_limit=None, filename=filename, spectralThreshold=5e-4)\n",
    "        else:\n",
    "            plotSignalAndSpectrum(time, real=values[\"inphase\"].numpy(), imag=values[\"quadrature\"].numpy(),\n",
    "                                  min_signal_limit=None, spectralThreshold=5e-4, filename=filename)\n",
    "\n",
    "'''\n",
    "def entanglementStateGoal(actual: tf.constant, index, dims, active_levels):\n",
    "    dim = active_levels ** len(dims)\n",
    "    actual_comp = tf_project_to_comp(\n",
    "        actual, dims=dims, index=index, outdims=[active_levels] * len(dims)\n",
    "    )\n",
    "    entropies = []\n",
    "    for state in [(0, 4)]: #, (0, 1), (1, 5), (4, 5)]:\n",
    "        psi_init = [[0] * dim]\n",
    "        psi_init[0][state[0]] = psi_init[0][state[1]] = 1.0 / np.sqrt(2)\n",
    "        init_state = tf.transpose(tf.constant(psi_init, tf.complex128))\n",
    "        #psi = np.zeros((dim, 1))\n",
    "        #psi[state[0], 0] = psi[state[1], 0] = 1 / np.sqrt(2)\n",
    "        #psi_init = tf.constant(psi, dtype=actual_comp.dtype)\n",
    "        #init_state = tf.transpose(tf.constant(psi_init, tf.complex128))\n",
    "        psi_actual = tf.matmul(actual_comp, init_state)\n",
    "        rho = densityMatrix(psi_actual)\n",
    "\n",
    "        # S(B) - S(BD)\n",
    "        rhoBD = partialTrace(rho, [1, 3])\n",
    "        #entropyBD = entanglementEntropy(rhoBD)\n",
    "        rhoB = partialTrace(rhoBD, [0])\n",
    "        entropyB = entanglementEntropy(rhoB)\n",
    "        entropies.append(entropyB)\n",
    "\n",
    "        # S(AB)\n",
    "        #rhoAB = partialTrace(rho, [0, 1])\n",
    "        #entropies.append(entanglementEntropy(rhoAB) / 2)\n",
    "    return 1 - np.max(entropies)\n",
    "'''\n",
    "\n",
    "def entanglementStateGoalTF(actual: tf.constant, index, dims, active_levels):\n",
    "    dim = active_levels ** len(dims)\n",
    "    actual_comp = tf_project_to_comp(\n",
    "        actual, dims=dims, index=index, outdims=[active_levels] * len(dims)\n",
    "    )\n",
    "\n",
    "    # initial and final state\n",
    "    psi = np.zeros((dim, 1))\n",
    "    for i in entanglementInitState:\n",
    "        psi[i, 0] = 1\n",
    "    psi /= np.linalg.norm(psi)\n",
    "    psi_init = tf.constant(psi, dtype=actual_comp.dtype)\n",
    "    psi_actual = tf.matmul(actual_comp, psi_init)\n",
    "    rho = densityMatrixTF(psi_actual[:, 0])\n",
    "\n",
    "    # calculate entropy\n",
    "    rhoBD = tf_project_to_comp(rho, dims=[2, 2, 2, 2], outdims=[0, 2, 0, 2])\n",
    "    #rhoBD = partialTraceTF(rho, [1, 3])\n",
    "    #entropyBD = entanglementEntropyTF(rhoBD) / 2\n",
    "    rhoB = partialTraceTF(rhoBD, [0])\n",
    "    entropyB = entanglementEntropyTF(rhoB)\n",
    "    #return (1.0 - entropyB + entropyBD) + 0.5 * (1.0 - tf.math.real(tf.norm(psi_actual)))\n",
    "    return (1.0 - entropyB) + 0.5 * (1.0 - tf.math.real(tf.norm(psi_actual)))\n",
    "\n",
    "    #rhoAB = partialTraceTF(rho, [0, 1])\n",
    "    #entropyAB = entanglementEntropyTF(rhoAB)\n",
    "    #return (2.0 - entropyAB) + 0.5 * (1.0 - tf.math.real(tf.norm(psi_actual)))\n",
    "\n",
    "\n",
    "def entanglementGoal(propagators: dict, instructions: dict, index, dims, active_levels=2, n_eval=-1):\n",
    "    infids = []\n",
    "    for gate, propagator in propagators.items():\n",
    "        infid = entanglementStateGoalTF(propagator, index, dims, active_levels)\n",
    "        infids.append(infid)\n",
    "    return tf.reduce_mean(infids)\n",
    "\n",
    "\n",
    "def optimise(output: DataOutput, qubits: List[chip.PhysicalComponent],\n",
    "             exp: Experiment, algorithm, options, gate: gates.Instruction) -> List[float]:\n",
    "    # set up the optimiser\n",
    "    opt = OptimalControl(\n",
    "        dir_path=output.getDirectory(),\n",
    "        fid_func=fidelities.unitary_infid_set,\n",
    "        #fid_func=entanglementGoal,\n",
    "        fid_subspace=[q.name for q in qubits],\n",
    "        pmap=exp.pmap,\n",
    "        algorithm=algorithm,\n",
    "        options=options,\n",
    "        run_name=gate.name,\n",
    "        fid_func_kwargs={\n",
    "            \"active_levels\": 4\n",
    "        }\n",
    "    )\n",
    "    exp.set_opt_gates([gate.get_key()])\n",
    "    opt.set_exp(exp)\n",
    "\n",
    "    # add the callback\n",
    "    infidelities = []\n",
    "\n",
    "    def fidelityCallback(index, fidelity):\n",
    "        print(index, fidelity)\n",
    "        infidelities.append(fidelity)\n",
    "\n",
    "    opt.set_callback(fidelityCallback)\n",
    "\n",
    "    # run optimisation\n",
    "    opt.optimize_controls()\n",
    "    print(opt.current_best_goal)\n",
    "    exp.pmap.print_parameters()\n",
    "\n",
    "    return infidelities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# coupling=30: f=4.6, anh=-200; f=4.32, anh=-350\n",
    "# f=4.5: anh=-200, coupling=33\n",
    "# Initialise the qubits and drive lines\n",
    "qubit_levels = [4, 4]\n",
    "qubit_frequencies = [5e9, 5e9]\n",
    "anharmonicities = [-300e6, -300e6]\n",
    "t1s = [25e-6, 25e-6]\n",
    "t2stars = [35e-6, 35e-6]\n",
    "qubit_temps = 50e-3\n",
    "couplingStrength = 20e6\n",
    "print(\"qubits frequencies: \", qubit_frequencies, \"anharmonicities: \", anharmonicities,\n",
    "      \"coupling: \", couplingStrength)\n",
    "\n",
    "level_labels_transmon = [\"|0,0\\\\rangle\", \"|0,1\\\\rangle\", \"|1,0\\\\rangle\", \"|1,1\\\\rangle\"]\n",
    "for i in range(len(level_labels_transmon), max(qubit_levels)):\n",
    "    level_labels_transmon.append(\"leakage\")\n",
    "level_labels = []\n",
    "level_labels_with_leakage = []\n",
    "level_labels_short = []\n",
    "for i in range(qubit_levels[0]):\n",
    "    for j in range(qubit_levels[1]):\n",
    "        if i > 3 or j > 3:\n",
    "            level_labels_with_leakage.append(\"leakage\")\n",
    "            level_labels_short.append(None)\n",
    "        else:\n",
    "            s = f\"${level_labels_transmon[i]},{level_labels_transmon[j]}$\"\n",
    "            level_labels.append(s)\n",
    "            level_labels_with_leakage.append(s)\n",
    "            level_labels_short.append(f\"{i},{j}\")\n",
    "level_labels_transmon = [f\"${x}$\" for x in level_labels_transmon]\n",
    "output = DataOutput(output_dir, file_suffix='before')\n",
    "\n",
    "qubits = createQubits(qubit_levels, qubit_frequencies, anharmonicities,\n",
    "                         t1s, t2stars, qubit_temps)\n",
    "coupling = createChainCouplings([couplingStrength], qubits)\n",
    "drives = createDrives(qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Mdl(qubits, coupling + drives)\n",
    "model.set_lindbladian(False)\n",
    "model.set_dressed(isDressed)\n",
    "model.set_FR(False)\n",
    "\n",
    "#energies = model.get_Hamiltonian().numpy().diagonal().real / (2 * np.pi)\n",
    "#print(\"energies: \", energies)\n",
    "qubitEnergies = [q.get_Hamiltonian().numpy().diagonal().real / (2 * np.pi) for q in qubits]\n",
    "qubitEnergies[0] = qubitEnergies[0][::qubit_levels[0]]\n",
    "qubitEnergies[1] = qubitEnergies[1][:qubit_levels[1]]\n",
    "qubitTransitions = [np.array([e[i + 1] - e[i] for i in range(len(e) - 1)]) for e in qubitEnergies]\n",
    "for i in range(len(qubits)):\n",
    "    print(f\"Qubit {i}:\")\n",
    "    print(qubitEnergies[i])\n",
    "    print(qubitTransitions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "stored_pmap = PMap()\n",
    "#stored_pmap.read_config(\"./optimised_params/2transmons_uncoupled/Z_q2_200ns.json\")\n",
    "stored_pmap.read_config(\"./optimised_params/CZ_f.json\")\n",
    "stored_params = stored_pmap.asdict()[\"CZ_t1_t2[0, 1]\"]\n",
    "\n",
    "stored_signal = generateSignalFromConfig(stored_params, sim_res=sim_res, awg_res=awg_res, useDRAG=useDRAG,\n",
    "                                         usePWC=usePWC, numPWCPieces=numPWCPieces, t_final=t_final)\n",
    "print(stored_signal[\"d1\"][\"values\"].shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "generator = createGenerator2LOs(drives, sim_res=sim_res, awg_res=awg_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Envelopes and carriers\n",
    "carrier_freqs = [\n",
    "    #[0.5*(qubitTransitions[0][1]+qubitTransitions[0][0]), 0.5*(qubitTransitions[0][2]+qubitTransitions[0][1])],\n",
    "    #[qubitTransitions[1][0], qubitTransitions[1][1]],\n",
    "    [40e6, 563e6],\n",
    "    #[qubitTransitions[1][0]],\n",
    "    #[0.5*(qubitTransitions[1][1]+qubitTransitions[1][0]), 0.5*(qubitTransitions[1][2]+qubitTransitions[1][1])],\n",
    "    #[qubitTransitions[1][0], qubitTransitions[1][1]]\n",
    "    #[qubitTransitions[1][0]]\n",
    "    [121e6, 644e6]\n",
    "]\n",
    "#df = couplingStrength ** 2 / (qubit_frequencies[0] - qubit_frequencies[1])\n",
    "#print(\"shift: \", df)\n",
    "#carrier_freqs[0] = [x + df for x in carrier_freqs[0]]\n",
    "#carrier_freqs[1] = [x - df for x in carrier_freqs[1]]\n",
    "\n",
    "carrier_framechange = [\n",
    "    [0.01, 0.01],\n",
    "    [0.01, 0.01]\n",
    "]\n",
    "pulse_t_final = [\n",
    "    [t_final, t_final],\n",
    "    [t_final, t_final]\n",
    "]\n",
    "pulse_sigmas = [\n",
    "    [t_final/5, t_final/5],\n",
    "    [t_final/5, t_final/5]\n",
    "]\n",
    "pulse_amps = [\n",
    "    [6, 6],\n",
    "    [0.1, 0.1]\n",
    "]\n",
    "pulse_deltas = [\n",
    "    [0.01, 0.01],\n",
    "    [0.01, 0.01]\n",
    "]\n",
    "pulse_xy_angles = [\n",
    "    [0.01, 0.01],\n",
    "    [0.01, 0.01]\n",
    "]\n",
    "pulse_freq_offsets = [\n",
    "    [0.01, 0.01],\n",
    "    [0.01, 0.01]\n",
    "]\n",
    "\n",
    "envelopes = []\n",
    "envelopesForDrive = {d.name: [] for d in drives}\n",
    "carriers = []\n",
    "carriersForDrive = {d.name: [] for d in drives}\n",
    "\n",
    "# copy carriers and envelopes from file\n",
    "for idx in []:\n",
    "    dstIdx = idx\n",
    "    srcIdx = idx\n",
    "    driveNameSrc = drives[srcIdx].name\n",
    "    driveNameDst = drives[dstIdx].name\n",
    "    stored_params_d = stored_params[\"drive_channels\"][driveNameSrc]\n",
    "    for i in range(0, len(carrier_freqs[idx])):\n",
    "        env: pulse.Envelope = copy.deepcopy(stored_params_d[f\"envelope_{driveNameSrc}_{i + 1}\"])\n",
    "        if useDRAG and not isinstance(env, EnvelopeDrag):\n",
    "            env = convertToDRAG(env)\n",
    "        if usePWC:\n",
    "            if env.shape != c3.libraries.envelopes.pwc:\n",
    "                env = convertToPWC(env, numPWCPieces)\n",
    "            elif len(env.params[\"inphase\"]) != numPWCPieces:\n",
    "                env = resamplePWC(env, numPWCPieces)\n",
    "        env.name = f\"envelope_{driveNameDst}_{i + 1}\"\n",
    "        #env = scaleGaussianEnvelope(env, t_final / env.params['t_final'].get_value())\n",
    "        #env.params[\"amp\"] = scaleQuantity(env.params[\"amp\"], 5)\n",
    "        #if dstIdx==1:\n",
    "        #    env.params[\"amp\"] = scaleQuantity(env.params[\"amp\"], 0.01)\n",
    "        envelopes.append(env)\n",
    "        envelopesForDrive[driveNameDst].append(env)\n",
    "\n",
    "        #shift = df if dstIdx == 0 else -df\n",
    "        carrier = copy.deepcopy(stored_params_d[f\"carrier_{driveNameSrc}_{i + 1}\"])\n",
    "        #print(\"Frequency: \", carrier.params[\"freq\"].get_value() / (2 * np.pi),\n",
    "        #      carrier.params[\"freq\"].get_limits()[0] / (2 * np.pi),\n",
    "        #      carrier.params[\"freq\"].get_limits()[1] / (2 * np.pi))\n",
    "        #print(stored_params_d[f\"carrier_{driveNameSrc}_{i + 1}\"])\n",
    "        #carrier.params[\"freq\"].set_value(\n",
    "        #    carrier.params[\"freq\"].get_value() / (2 * np.pi) + shift\n",
    "        #)\n",
    "        #carrier.params[\"freq\"] = Qty(\n",
    "        #    value=carrier_freqs[dstIdx][i],\n",
    "        #    min_val=0.95 * carrier_freqs[dstIdx][i],\n",
    "        #    max_val=1.05 * carrier_freqs[dstIdx][i],\n",
    "        #    unit=\"Hz 2pi\"\n",
    "        #)\n",
    "        carrier.name = f\"carrier_{driveNameDst}_{i + 1}\"\n",
    "        carriers.append(carrier)\n",
    "        carriersForDrive[driveNameDst].append(carrier)\n",
    "\n",
    "# create carriers and envelopes\n",
    "for idx in [0, 1]:\n",
    "    for i in range(0, len(carrier_freqs[idx])):\n",
    "        env = createGaussianPulse(\n",
    "            t_final=pulse_t_final[idx][i],\n",
    "            sigma=pulse_sigmas[idx][i],\n",
    "            amp=pulse_amps[idx][i],\n",
    "            delta=pulse_deltas[idx][i],\n",
    "            xy_angle=pulse_xy_angles[idx][i],\n",
    "            freq_off=pulse_freq_offsets[idx][i],\n",
    "            useDrag=useDRAG\n",
    "        )\n",
    "        #env = createNoDriveEnvelope(t_final)\n",
    "        if usePWC:\n",
    "            env = convertToPWC(env, numPWCPieces)\n",
    "        env.name = f\"envelope_{drives[idx].name}_{i + 1}\"\n",
    "        #env.params[\"amp\"] = scaleQuantity(env.params[\"amp\"], 0.2)\n",
    "        envelopes.append(env)\n",
    "        envelopesForDrive[drives[idx].name].append(env)\n",
    "\n",
    "        carrier_parameters = {\n",
    "            \"freq\": Qty(value=carrier_freqs[idx][i], min_val=0.98 * carrier_freqs[idx][i],\n",
    "                        max_val=1.02 * carrier_freqs[idx][i], unit=\"Hz 2pi\"),\n",
    "            \"framechange\": Qty(value=carrier_framechange[idx][i], min_val=-np.pi, max_val=3 * np.pi, unit=\"rad\"),\n",
    "        }\n",
    "        carrier = pulse.Carrier(\n",
    "            name=f\"carrier_{drives[idx].name}_{i + 1}\",\n",
    "            desc=\"Frequency of the local oscillator\",\n",
    "            params=carrier_parameters,\n",
    "        )\n",
    "        carriers.append(carrier)\n",
    "        carriersForDrive[drives[idx].name].append(carrier)\n",
    "\n",
    "print(\"carrier: \", [[carrier.params[\"freq\"] for carrier in carriers] for carriers in carriersForDrive.values()])\n",
    "print(\"amp: \", [[env.params[\"amp\"] for env in envelopes] for envelopes in envelopesForDrive.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Gate instructions\n",
    "#ideal_gate_single = qt_utils.np_kron_n([constants.Id, constants.GATES[\"rx90p\"]])\n",
    "#ideal_gate_single = gates.GATES[\"iswap\"]\n",
    "#ideal_gate = np.array(\n",
    "#    [[1, 0, 0, 0], [0, 0, 0, 1j], [0, 0, 1, 0], [0, 1j, 0, 0]], dtype=np.complex128\n",
    "#)\n",
    "#ideal_gate_Unity = qt_utils.np_kron_n([constants.Id, constants.Id])\n",
    "#ideal_gate_Z = qt_utils.np_kron_n([constants.Id, constants.Z])\n",
    "#ideal_gate = qt_utils.np_kron_n([ideal_gate_Unity, ideal_gate_Unity])\n",
    "#ideal_gate = scipy.linalg.block_diag([ideal1, ideal_gate_Unity])\n",
    "ideal_gate = custom_gates.GATE_iSWAP_t1q2_t2q2\n",
    "#ideal_gate = constants.GATES[\"cx\"]\n",
    "printMatrix(ideal_gate, level_labels, \"ideal_gate\", output)\n",
    "\n",
    "gate = gates.Instruction(\n",
    "    name=\"iswap_t1q2_t2q2\",\n",
    "    #name=\"unity\",\n",
    "    targets=[0, 1],\n",
    "    t_start=0.0,\n",
    "    t_end=t_final,\n",
    "    channels=[d.name for d in drives],\n",
    "    ideal=ideal_gate,\n",
    ")\n",
    "for drive in drives:\n",
    "    for env in envelopesForDrive[drive.name]:\n",
    "        gate.add_component(copy.deepcopy(env), drive.name)\n",
    "    for carrier in carriersForDrive[drive.name]:\n",
    "        gate.add_component(copy.deepcopy(carrier), drive.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# all energy levels with labels\n",
    "stateEnergies = []\n",
    "H = model.get_Hamiltonian().numpy()\n",
    "evals,evecs = scipy.linalg.eig(H)\n",
    "evals = evals.real / (2 * np.pi)\n",
    "indices = [np.argmax(np.round(evecs[i], 2)) for i in range(len(evals))]\n",
    "for i, x in enumerate(level_labels_short):\n",
    "    if level_labels_short[i] is not None:\n",
    "        energy = evals[indices[i]]\n",
    "        stateEnergies.append((energy, x))\n",
    "\n",
    "# all energy transitions\n",
    "items = sorted(stateEnergies, key=lambda x: x[0])\n",
    "transitions = []\n",
    "for i in range(len(items)):\n",
    "    for j in range(len(items)):\n",
    "        if i != j:\n",
    "            #print(i, j)\n",
    "            E = items[j][0] - items[i][0]\n",
    "            if E > 0:\n",
    "                transitions.append((E, items[i][1] + \" - \" + items[j][1]))\n",
    "\n",
    "#for t in transitions:\n",
    "#    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up the experiment\n",
    "parameter_map = PMap(instructions=[gate], model=model, generator=generator)\n",
    "exp = Exp(pmap=parameter_map, sim_res=sim_res)\n",
    "exp.set_opt_gates([gate.get_key()])\n",
    "\n",
    "unitaries = exp.compute_propagators()\n",
    "printPropagator(exp, gate, level_labels_with_leakage, output)\n",
    "#printAllSignals(exp, qubit, output, directory=\"devices_before\")\n",
    "printSignal(exp, qubits, gate, output=output, states=transitions)\n",
    "#printMatrix(model.get_Hamiltonian(), level_labels_with_leakage, 'Hamiltonian', output)\n",
    "#printMatrix(model.get_Hamiltonian() / np.max(model.get_Hamiltonian()), level_labels_with_leakage, 'Hamiltonian_scaled', output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the initial state\n",
    "psi_init = [[0] * model.tot_dim]\n",
    "for i in entanglementInitStateFull:\n",
    "    psi_init[0][i] = 1\n",
    "psi_init /= np.linalg.norm(psi_init)\n",
    "print(\"initial state: \", psi_init)\n",
    "init_state = tf.transpose(tf.constant(psi_init, tf.complex128))\n",
    "sequence = [gate.get_key()]\n",
    "\n",
    "printTimeEvolution(exp, init_state, gate, level_labels, output)\n",
    "printEntanglementEvolution(exp, gate, output)\n",
    "parameter_map.write_config(output.createFileName(\"parameter_map\", \"json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the parameters to be optimised and initialise the optimiser\n",
    "opt_map = []\n",
    "for drive in drives:\n",
    "    for env in envelopesForDrive[drive.name]:\n",
    "        opt_map.append([(gate.get_key(), drive.name, env.name, \"amp\")])\n",
    "        opt_map.append([(gate.get_key(), drive.name, env.name, \"freq_offset\")])\n",
    "        opt_map.append([(gate.get_key(), drive.name, env.name, \"xy_angle\")])\n",
    "        if useDRAG:\n",
    "            opt_map.append([(gate.get_key(), drive.name, env.name, \"delta\")])\n",
    "        if usePWC:\n",
    "            opt_map.append([(gate.get_key(), drive.name, env.name, \"inphase\")])\n",
    "            opt_map.append([(gate.get_key(), drive.name, env.name, \"quadrature\")])\n",
    "            #opt_map.append([(gate.get_key(), drive.name, env.name, \"t_bin_end\")])\n",
    "        else:\n",
    "            opt_map.append([(gate.get_key(), drive.name, env.name, \"sigma\")])\n",
    "            opt_map.append([(gate.get_key(), drive.name, env.name, \"t_final\")])\n",
    "    for carrier in carriersForDrive[drive.name]:\n",
    "        opt_map.append([(gate.get_key(), drive.name, carrier.name, \"freq\")])\n",
    "    #    #opt_map.append([(gate.get_key(), drive.name, carrier.name, \"framechange\")])\n",
    "parameter_map.set_opt_map(opt_map)\n",
    "parameter_map.print_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "infidelities = []\n",
    "\n",
    "for algorithm in selected_algorithms:\n",
    "    if algorithm == ALGORITHM_LBFGS:\n",
    "        infidelities = optimise(output, qubits, exp, algorithms.lbfgs, {\n",
    "            \"maxfun\": 2000,\n",
    "            \"ftol\": 1e-6\n",
    "        }, gate)\n",
    "    elif algorithm == ALGORITHM_LBFGS_GRAD_FREE:\n",
    "        infidelities = optimise(output, qubits, exp, algorithms.lbfgs_grad_free, {\n",
    "            \"maxfun\": 500,\n",
    "            \"gtol\": 1e-4,\n",
    "            \"ftol\": 1e-4\n",
    "        }, gate)\n",
    "    elif algorithm == ALGORITHM_CMAES:\n",
    "        infidelities = optimise(output, qubits, exp, algorithms.cmaes, {\n",
    "            \"popsize\": 15,\n",
    "            \"spread\": 0.02,\n",
    "            \"maxfevals\": 2000,\n",
    "            \"init_point\": \"True\",\n",
    "            \"stop_at_sigma\": 1e-3,\n",
    "            \"stop_at_convergence\": 20\n",
    "        }, gate)\n",
    "    elif algorithm == ALGORITHM_GCMAES:\n",
    "        infidelities = optimise(output, qubits, exp, algorithms.gcmaes, {\n",
    "            \"cmaes\": {\"popsize\": 12, \"spread\": 0.05, \"maxfevals\": 20,\n",
    "                      \"init_point\": \"True\", \"stop_at_sigma\": 1e-4, \"stop_at_convergence\": 20},\n",
    "            \"lbfgs\": {\"maxfun\": 500, \"ftol\": 1e-6}\n",
    "        }, gate)\n",
    "    else:\n",
    "        print(\"Unknown algorithm: \", algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "output = DataOutput(output_dir, file_suffix='after')\n",
    "plotData(np.arange(len(infidelities)), infidelities, xlabel=\"Step\",\n",
    "         ylabel=\"Infidelity\", filename=output.createFileName(\"convergence\", \"svg\"))\n",
    "printSignal(exp, qubits, gate, output=output, states=transitions)\n",
    "#printAllSignals(exp, qubits, output, directory=\"devices_after\")\n",
    "printPropagator(exp, gate, level_labels_with_leakage, output, savePartials=False)\n",
    "printTimeEvolution(exp, init_state, gate, level_labels, output)\n",
    "printEntanglementEvolution(exp, gate, output)\n",
    "parameter_map.write_config(output.createFileName(\"parameter_map\", \"json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import tensorflow as tf\n",
    "\n",
    "def makhlinInvariants(U: tf.Tensor) -> tf.Tensor:\n",
    "    # transform to bell basis\n",
    "    Q = tf.constant(np.matrix([\n",
    "        [1, 0, 0, 1j],\n",
    "        [0, 1j, 1, 0],\n",
    "        [0, 1j, -1, 0],\n",
    "        [1, 0, 0, -1j]\n",
    "    ]) / np.sqrt(2))\n",
    "    Ub = tf.matmul(tf.linalg.adjoint(Q), tf.matmul(U, Q))\n",
    "\n",
    "    # calculate characteristics\n",
    "    m = tf.matmul(tf.transpose(Ub), Ub)\n",
    "    tr = tf.linalg.trace(m)\n",
    "    tr2 = tf.linalg.trace(m ** 2)\n",
    "    trSq = tr ** 2\n",
    "    g1 = tf.math.real(trSq) / 16.0\n",
    "    g2 = tf.math.imag(trSq) / 16.0\n",
    "    g3 = tf.math.real((trSq - tr2)) / 4.0\n",
    "    return tf.concat([g1, g2, g3], 0)\n",
    "\n",
    "\n",
    "def makhlinDistance(gs: tf.Tensor) -> tf.Tensor:\n",
    "    roots = np.roots([1, -g3, 4 * np.sqrt(g1 ** 2 + g2 ** 2) - 1, g3 - 4 * g1]).real()\n",
    "    roots = np.round(roots, 5)\n",
    "    z = np.sort(roots)\n",
    "    print(\"roots: \", roots)\n",
    "    print(\"sorted: \", z)\n",
    "\n",
    "    d = g3 * np.sqrt(g1 ** 2 + g2 ** 2) - g1\n",
    "    s = np.pi - np.arccos(z[0]) - np.arccos(z[2])\n",
    "    print(\"d: \", d, \"s: \", s)\n",
    "    if d>0 and s>0:\n",
    "        return d\n",
    "    elif d<0 and s<0:\n",
    "        return -d\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "sqrtSWAP = np.matrix([\n",
    "    [1, 0, 0, 0],\n",
    "    [0,(1+1j)/2.0,(1-1j)/2.0,0],\n",
    "    [0,(1-1j)/2.0,(1+1j)/2.0,0],\n",
    "    [0,0,0,1],\n",
    "])\n",
    "SWAP = np.matrix([\n",
    "    [1,0,0,0],\n",
    "    [0,0,1,0],\n",
    "    [0,1,0,0],\n",
    "    [0,0,0,1]\n",
    "])\n",
    "CNOT = np.matrix([\n",
    "    [1,0,0,0],\n",
    "    [0,1,0,0],\n",
    "    [0,0,0,1],\n",
    "    [0,0,1,0]\n",
    "])\n",
    "UNITY = np.matrix([\n",
    "    [1,0,0,0],\n",
    "    [0,1,0,0],\n",
    "    [0,0,1,0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "gs = makhlinInvariants(tf.constant(UNITY, dtype=tf.complex128))\n",
    "print(gs)\n",
    "#dist = makhlinDistance(g1, g2, g3)\n",
    "#print(dist)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}