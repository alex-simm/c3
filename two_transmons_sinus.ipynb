{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Two transmon optimisation with cosine signal\n",
    "Same as two_transmons_4LOs.ipynb, but the signal is created by a superposition of cosines. This can be used to optimise a large superposition of frequency peaks."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import c3\n",
    "import c3.libraries.algorithms as algorithms\n",
    "import c3.libraries.fidelities as fidelities\n",
    "import c3.utils.qt_utils as qt_utils\n",
    "from c3.signal.pulse import EnvelopeDrag\n",
    "from c3.utils.tf_utils import tf_project_to_comp\n",
    "import four_level_transmons.custom_gates as custom_gates\n",
    "from c3.experiment import Experiment as Exp\n",
    "from c3.model import Model as Mdl\n",
    "from c3.optimizers.optimalcontrol import OptimalControl\n",
    "from c3.parametermap import ParameterMap as PMap\n",
    "from four_level_transmons.DataOutput import DataOutput\n",
    "from four_level_transmons.custom_envelopes import *\n",
    "from four_level_transmons.plotting import *\n",
    "from four_level_transmons.utilities import *\n",
    "from four_level_transmons.blackbox import generateSignalFromConfig\n",
    "from four_level_transmons.notebook_utils import *\n",
    "tf.config.run_functions_eagerly(True)\n",
    "np.set_printoptions(linewidth=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "FREQS = None\n",
    "INPUT_FILE = None\n",
    "if len(sys.argv[1:]) > 3 and \"ipykernel_launcher\" not in sys.argv[0]:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--output\", help=\"Output directory\")\n",
    "    parser.add_argument(\"--config\", help=\"File with previous configuration\")\n",
    "    parser.add_argument(\"--freqs1\", help=\"New number of frequencies on qubit1\")\n",
    "    parser.add_argument(\"--freqs2\", help=\"New number of frequencies on qubit2\")\n",
    "    args = parser.parse_args()\n",
    "    output_dir = args.output\n",
    "    INPUT_FILE = args.config\n",
    "    FREQS = (int(args.freqs1), int(args.freqs2))\n",
    "    print(\"Output directory: \", output_dir)\n",
    "    print(\"Number of frequencies: \", FREQS)\n",
    "elif len(sys.argv[1:]) > 0 and \"ipykernel_launcher\" not in sys.argv[0]:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--output\", help=\"Output directory\")\n",
    "    args = parser.parse_args()\n",
    "    output_dir = args.output\n",
    "    print(\"Output directory: \", output_dir)\n",
    "else:\n",
    "    print(\"=========== WARNING: no output directory specified ============\")\n",
    "    output_dir = \"./output\"\n",
    "output = DataOutput(output_dir, file_suffix='before')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# general settings\n",
    "numPWCPieces = 60\n",
    "usePWC = False\n",
    "useDRAG = True\n",
    "t_final = 1000e-9 #1e-11\n",
    "sim_res = 20e9 #1000e9\n",
    "awg_res = numPWCPieces / t_final if usePWC else 50e9 #1000e9\n",
    "isDressed = True\n",
    "useFR = True\n",
    "\n",
    "ALGORITHM_LBFGS = 0\n",
    "ALGORITHM_LBFGS_GRAD_FREE = 1\n",
    "ALGORITHM_CMAES = 2\n",
    "ALGORITHM_GCMAES = 3\n",
    "selected_algorithms = [\n",
    "    #(ALGORITHM_LBFGS, {\"maxfun\": 50}),\n",
    "    #(ALGORITHM_CMAES, {}),\n",
    "    (ALGORITHM_LBFGS, {\"maxfun\": 1500, \"ftol\": 2e-6})\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if INPUT_FILE is None:\n",
    "    #INPUT_FILE = \"./optimised_params/CCCX_1110-1111_200ns_full.json\"\n",
    "    #INPUT_FILE = \"./optimised_params/fourier basis 5 levels/100 freqs/unity.json\"\n",
    "    INPUT_FILE = \"./optimised_params/fourier basis 5 levels, 500ns, RF/200 freqs/CNOT.json\"\n",
    "#IDEAL_GATE, IDEAL_GATE_NAME = np.eye(16), \"unity\"\n",
    "#IDEAL_GATE, IDEAL_GATE_NAME = custom_gates.GATE_CNOT_t1q2_t2q2, \"cnot_t1q2_t2q2\"\n",
    "IDEAL_GATE, IDEAL_GATE_NAME = custom_gates.GATE_iCNOT_t1q2_t2q2, \"icnot_t1q2_t2q2\"\n",
    "#IDEAL_GATE, IDEAL_GATE_NAME = custom_gates.GATE_iSWAP_t1q2_t2q2, \"iswap_t1q2_t2q2\"\n",
    "#IDEAL_GATE, IDEAL_GATE_NAME = custom_gates.GATE_SQRTiSWAP_t1q2_t2q2, \"sqrtiswap_t1q2_t2q2\"\n",
    "#IDEAL_GATE, IDEAL_GATE_NAME = custom_gates.GATE_CZ_t1q2_t2q2, \"cz_t1_t2\"\n",
    "#IDEAL_GATE, IDEAL_GATE_NAME = custom_gates.GATE_UNIVERSAL_ENTANGLER, \"universal_entangler\"\n",
    "#IDEAL_GATE, IDEAL_GATE_NAME = custom_gates.GATE_4QUBIT_1110_1111, \"cccnot_1110\"\n",
    "\n",
    "OPTIMISE_TFINAL = False\n",
    "FORCE_XY_ANGLE = False\n",
    "FORCE_FREQ_OFFSET = False\n",
    "FORCE_DELTA = 0.1\n",
    "OPTIMISE_FREQUENCIES = True\n",
    "\n",
    "#NUM_PEAKS = (-1, 15)\n",
    "#INCLUDED_INDICES = ([1,2,3,4,5,6,7,8,9,10,11,12,13,14], None)\n",
    "\n",
    "if FREQS is not None:\n",
    "    NUM_PEAKS = FREQS\n",
    "else:\n",
    "    NUM_PEAKS = (-1, -1)\n",
    "#NUM_PEAKS = (-1, -1)\n",
    "INCLUDED_INDICES = (None, None)\n",
    "#INCLUDED_INDICES = (np.array([1,2,3,4,5,6,7,8,9,10,11,12]), None)\n",
    "\n",
    "#SPECTRAL_RANGE = (0.1e9, 5.5e9)\n",
    "#SPECTRAL_RANGE = (2.5e9, 5.5e9)\n",
    "SPECTRAL_RANGE = (-1, -1)\n",
    "SELECTED_INDEX = (-1, -1)\n",
    "\n",
    "OPTIMISABLE_DRIVES = [0, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "entanglementInitState = [0, 1]\n",
    "entanglementInitStateFull = [0, 1]\n",
    "\n",
    "\n",
    "def stateEntropyAB(state: tf.Tensor):\n",
    "    rho = densityMatrix(state)\n",
    "    if state.shape[0] > 16:\n",
    "        rho = tf_project_to_comp(rho, dims=qubit_levels, outdims=[4, 4])\n",
    "    rhoBD = tf_project_to_comp(rho, dims=[2, 2, 2, 2], outdims=[0, 2, 0, 2])\n",
    "    #rhoBD = partialTrace(rho, [1, 3])\n",
    "    rhoB = partialTrace(rhoBD, [0])\n",
    "    #rhoAB = partialTrace(rho, [0, 1])\n",
    "    return entanglementEntropy(rhoB)  #- entanglementEntropy(rhoBD)\n",
    "\n",
    "\n",
    "def printEntanglementEvolution(exper: Experiment, gate: gates.Instruction, output: DataOutput):\n",
    "    entropies = []\n",
    "    #for state in [(0, 1), (0, 5), (1, 6), (5, 6)]:\n",
    "    for state in [(0, 1), (0, 4), (1, 5), (4, 5)]:\n",
    "        #for state in [(0, 4), (5, 6), (10, 11), (12, 13)]:\n",
    "        psi_init = np.zeros(shape=(model.tot_dim,))\n",
    "        psi_init[state[0]] = psi_init[state[1]] = 1 / np.sqrt(2)\n",
    "        entropy = calculateObservable(exper, np.array(psi_init), [gate.get_key()], stateEntropyAB)\n",
    "        entropies.append(entropy)\n",
    "    entropies = np.array(entropies)\n",
    "    plotPopulation(exper, entropies, sequence=[gate.get_key()],\n",
    "                   labels=[\"00+01\", \"00+10\", \"01+11\", \"10+11\"],\n",
    "                   filename=output.createFileName(\"entanglement\", \"svg\"),\n",
    "                   labelY=\"Entropy\")\n",
    "\n",
    "\n",
    "'''\n",
    "def entanglementStateGoal(actual: tf.constant, index, dims, active_levels):\n",
    "    dim = active_levels ** len(dims)\n",
    "    actual_comp = tf_project_to_comp(\n",
    "        actual, dims=dims, index=index, outdims=[active_levels] * len(dims)\n",
    "    )\n",
    "    entropies = []\n",
    "    for state in [(0, 4)]: #, (0, 1), (1, 5), (4, 5)]:\n",
    "        psi_init = [[0] * dim]\n",
    "        psi_init[0][state[0]] = psi_init[0][state[1]] = 1.0 / np.sqrt(2)\n",
    "        init_state = tf.transpose(tf.constant(psi_init, tf.complex128))\n",
    "        #psi = np.zeros((dim, 1))\n",
    "        #psi[state[0], 0] = psi[state[1], 0] = 1 / np.sqrt(2)\n",
    "        #psi_init = tf.constant(psi, dtype=actual_comp.dtype)\n",
    "        #init_state = tf.transpose(tf.constant(psi_init, tf.complex128))\n",
    "        psi_actual = tf.matmul(actual_comp, init_state)\n",
    "        rho = densityMatrix(psi_actual)\n",
    "\n",
    "        # S(B) - S(BD)\n",
    "        rhoBD = partialTrace(rho, [1, 3])\n",
    "        #entropyBD = entanglementEntropy(rhoBD)\n",
    "        rhoB = partialTrace(rhoBD, [0])\n",
    "        entropyB = entanglementEntropy(rhoB)\n",
    "        entropies.append(entropyB)\n",
    "\n",
    "        # S(AB)\n",
    "        #rhoAB = partialTrace(rho, [0, 1])\n",
    "        #entropies.append(entanglementEntropy(rhoAB) / 2)\n",
    "    return 1 - np.max(entropies)\n",
    "'''\n",
    "\n",
    "def entanglementStateGoalTF(actual: tf.constant, index, dims, active_levels):\n",
    "    dim = active_levels ** len(dims)\n",
    "    actual_comp = tf_project_to_comp(\n",
    "        actual, dims=dims, index=index, outdims=[active_levels] * len(dims)\n",
    "    )\n",
    "\n",
    "    # initial and final state\n",
    "    psi = np.zeros((dim, 1))\n",
    "    for i in entanglementInitState:\n",
    "        psi[i, 0] = 1\n",
    "    psi /= np.linalg.norm(psi)\n",
    "    psi_init = tf.constant(psi, dtype=actual_comp.dtype)\n",
    "    psi_actual = tf.matmul(actual_comp, psi_init)\n",
    "    rho = densityMatrixTF(psi_actual[:, 0])\n",
    "\n",
    "    # calculate entropy\n",
    "    rhoBD = tf_project_to_comp(rho, dims=[2, 2, 2, 2], outdims=[0, 2, 0, 2])\n",
    "    #rhoBD = partialTraceTF(rho, [1, 3])\n",
    "    #entropyBD = entanglementEntropyTF(rhoBD) / 2\n",
    "    rhoB = partialTraceTF(rhoBD, [0])\n",
    "    entropyB = entanglementEntropyTF(rhoB)\n",
    "    #return (1.0 - entropyB + entropyBD) + 0.5 * (1.0 - tf.math.real(tf.norm(psi_actual)))\n",
    "    return (1.0 - entropyB) + 0.5 * (1.0 - tf.math.real(tf.norm(psi_actual)))\n",
    "\n",
    "    #rhoAB = partialTraceTF(rho, [0, 1])\n",
    "    #entropyAB = entanglementEntropyTF(rhoAB)\n",
    "    #return (2.0 - entropyAB) + 0.5 * (1.0 - tf.math.real(tf.norm(psi_actual)))\n",
    "\n",
    "\n",
    "def transmonEntanglementGoal(actual: tf.constant, index, dims, active_levels):\n",
    "    actual_comp = tf_project_to_comp(\n",
    "        actual, dims=dims, index=index, outdims=[active_levels] * len(dims)\n",
    "    )\n",
    "    rho = tf.einsum('ijkj->ik', tf.reshape(actual_comp, shape=[4,4,4,4]))\n",
    "    entropy = entanglementEntropyTF(rho)\n",
    "    return 1.0 - entropy\n",
    "\n",
    "\n",
    "def entanglementGoal(propagators: dict, instructions: dict, index, dims, active_levels=2, n_eval=-1):\n",
    "    infids = []\n",
    "    for gate, propagator in propagators.items():\n",
    "        infid = transmonEntanglementGoal(propagator, index, dims, active_levels)\n",
    "        infids.append(infid)\n",
    "    return tf.reduce_mean(infids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# coupling=30: f=4.6, anh=-200; f=4.32, anh=-350\n",
    "# f=4.5: anh=-200, coupling=33\n",
    "# Initialise the qubits and drive lines\n",
    "qubit_levels = [5, 5]\n",
    "qubit_frequencies = [5e9, 4.5e9]\n",
    "anharmonicities = [-300e6, -250e6]\n",
    "t1s = [25e-6, 25e-6]\n",
    "t2stars = [35e-6, 35e-6]\n",
    "qubit_temps = [50e-3, 50e-3]\n",
    "couplingStrength = 20e6\n",
    "print(\"qubits frequencies: \", qubit_frequencies, \"anharmonicities: \", anharmonicities,\n",
    "      \"coupling: \", couplingStrength)\n",
    "\n",
    "level_labels_transmon = [\"|0,0\\\\rangle\", \"|0,1\\\\rangle\", \"|1,0\\\\rangle\", \"|1,1\\\\rangle\"]\n",
    "for i in range(len(level_labels_transmon), max(qubit_levels)):\n",
    "    level_labels_transmon.append(\"leakage\")\n",
    "level_labels = []\n",
    "level_labels_with_leakage = []\n",
    "level_labels_short = []\n",
    "for i in range(qubit_levels[0]):\n",
    "    for j in range(qubit_levels[1]):\n",
    "        if i > 3 or j > 3:\n",
    "            level_labels_with_leakage.append(\"leakage\")\n",
    "        else:\n",
    "            s = f\"${level_labels_transmon[i]},{level_labels_transmon[j]}$\"\n",
    "            level_labels.append(s)\n",
    "            level_labels_with_leakage.append(s)\n",
    "        level_labels_short.append(f\"{i},{j}\")\n",
    "level_labels_transmon = [f\"${x}$\" for x in level_labels_transmon]\n",
    "\n",
    "qubits = createQubits(qubit_levels, qubit_frequencies, anharmonicities,\n",
    "                         t1s, t2stars, qubit_temps)\n",
    "coupling = createChainCouplings([couplingStrength], qubits)\n",
    "drives = createDrives(qubits)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Mdl(qubits, coupling + drives)\n",
    "model.set_lindbladian(False)\n",
    "model.set_dressed(isDressed)\n",
    "model.set_FR(useFR)\n",
    "\n",
    "#energies = model.get_Hamiltonian().numpy().diagonal().real / (2 * np.pi)\n",
    "#print(\"energies: \", energies)\n",
    "qubitEnergies = [q.get_Hamiltonian().numpy().diagonal().real / (2 * np.pi) for q in qubits]\n",
    "qubitEnergies[0] = qubitEnergies[0][::qubit_levels[0]]\n",
    "qubitEnergies[1] = qubitEnergies[1][:qubit_levels[1]]\n",
    "qubitTransitions = [np.array([e[i + 1] - e[i] for i in range(len(e) - 1)]) for e in qubitEnergies]\n",
    "for i in range(len(qubits)):\n",
    "    print(f\"Qubit {i}:\")\n",
    "    print(qubitEnergies[i])\n",
    "    print(qubitTransitions[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getFourierBasisFromDirectTransitions(qubitTransitions):\n",
    "    allTransitions = [qubitTransitions[0][0], qubitTransitions[0][1], qubitTransitions[0][2], qubitTransitions[1][0], qubitTransitions[1][1], qubitTransitions[1][2]]\n",
    "    allAmps = [0.2, 0.02, 0.2, 1, 0.1, 1]\n",
    "    selectedFreqsMap = {\"d1\": np.array(allTransitions), \"d2\": np.array(allTransitions)}\n",
    "    selectedAmpsMap = {\"d1\": 1e8 * np.array(allAmps), \"d2\": 1e7 * np.array(allAmps)}\n",
    "    selectedPhasesMap = {\"d1\": np.zeros_like(allTransitions), \"d2\": np.zeros_like(allTransitions)}\n",
    "    return selectedFreqsMap, selectedAmpsMap, selectedPhasesMap\n",
    "\n",
    "def getFourierBasisFromModel(levelTransitions: List[float], spectralRange: Tuple[float,float]=(3.6e9,5.0e9)) -> Tuple[Dict, Dict, Dict]:\n",
    "    selectedFrequencies = []\n",
    "    for t in levelTransitions:\n",
    "        if spectralRange[0] < t[0] < spectralRange[1]:\n",
    "            selectedFrequencies.append(t[0])\n",
    "    selectedFrequencies = np.sort(selectedFrequencies)\n",
    "    selectedFreqsMap = {\"d1\": selectedFrequencies, \"d2\": selectedFrequencies}\n",
    "    selectedAmpsMap = {\"d1\": 0.5e8 * np.ones_like(selectedFrequencies), \"d2\": 0.5e7 * np.ones_like(selectedFrequencies)}\n",
    "    selectedPhasesMap = {\"d1\": 0.1 * np.ones_like(selectedFrequencies), \"d2\": 0.1 * np.ones_like(selectedFrequencies)}\n",
    "    return selectedFreqsMap, selectedAmpsMap, selectedPhasesMap\n",
    "\n",
    "\n",
    "def getFourierBasisFromSignal(filename: str) -> Tuple[Dict, Dict, Dict]:\n",
    "    stored_pmap = PMap()\n",
    "    stored_pmap.read_config(filename)\n",
    "    stored_params = stored_pmap.asdict()[list(stored_pmap.asdict().keys())[0]]\n",
    "    stored_signal = generateSignalFromConfig(stored_params, sim_res=sim_res, awg_res=numPWCPieces / t_final,\n",
    "                                             useDRAG=False,\n",
    "                                             usePWC=True, numPWCPieces=60, t_final=t_final)\n",
    "    selectedFreqsMap = {}\n",
    "    selectedAmpsMap = {}\n",
    "    selectedPhasesMap = {}\n",
    "    for i, drive in enumerate(list(stored_signal.keys())):\n",
    "        signal = stored_signal[drive]\n",
    "\n",
    "        ts = signal[\"ts\"].numpy()\n",
    "        values = signal[\"values\"].numpy()\n",
    "        freq = np.fft.rfftfreq(len(ts), ts[-1] / len(ts))[1:]\n",
    "        freq_signal = np.fft.rfft(values)[1:]\n",
    "        #freq = np.fft.rfftfreq(len(ts), ts[-1] / len(ts))\n",
    "        #freq_signal = np.abs(np.fft.rfft(values))\n",
    "        #peaks, amps = findFrequencyPeaks(signal[\"ts\"].numpy(), signal[\"values\"].numpy(), 50, normalise=True)\n",
    "        selectedFreqsMap[drive] = freq\n",
    "        selectedAmpsMap[drive] = np.abs(freq_signal)\n",
    "        selectedPhasesMap[drive] = np.angle(freq_signal)\n",
    "        print(\"selected frequencies: \", len(selectedFreqsMap[drive]))\n",
    "        print(selectedFreqsMap[drive])\n",
    "    return selectedFreqsMap, selectedAmpsMap, selectedPhasesMap\n",
    "\n",
    "\n",
    "def getConfigurationFromFile(filename: str, spectralRange: Tuple[float, float], numPeaks: Tuple[int, int],\n",
    "                             selectedIndex=(None, None), includedIndices=(None, None),\n",
    "                             addFreqs: List[Tuple[float, float, float]] = None) -> Dict:\n",
    "    stored_pmap = PMap()\n",
    "    stored_pmap.read_config(filename)\n",
    "    stored_params = stored_pmap.asdict()[list(stored_pmap.asdict().keys())[0]]\n",
    "    driveChannels = stored_params[\"drive_channels\"]\n",
    "    for driveIdx, driveName in enumerate(driveChannels.keys()):\n",
    "        envelope = driveChannels[driveName][f\"envelope_{driveName}\"]\n",
    "        freqs = envelope.params[\"freqs\"].get_value().numpy() / (2 * np.pi)\n",
    "        amps = envelope.params[\"amps\"].get_value().numpy()\n",
    "        phases = envelope.params[\"phases\"].get_value().numpy()\n",
    "\n",
    "        # restrict to spectral range\n",
    "        if spectralRange is not None and len(spectralRange) > 1 and spectralRange[0] >= 0 and spectralRange[1] >= 0:\n",
    "            indices = np.all([freqs > spectralRange[0], freqs < spectralRange[1]], 0)\n",
    "            freqs = freqs[indices]\n",
    "            amps = amps[indices]\n",
    "            phases = phases[indices]\n",
    "            print(f\"Drive {driveName}: after restriction to range: {len(indices)}\")\n",
    "\n",
    "        # find peaks\n",
    "        #if numPeaks is not None and numPeaks > 0:\n",
    "        #    peaks = find_peaks(amps)[0]\n",
    "        #    freqs = freqs[peaks]\n",
    "        #    amps = amps[peaks]\n",
    "        #    phases = phases[peaks]\n",
    "        #    print(f\"Drive {driveName}: peaks found: {len(peaks)}\")\n",
    "\n",
    "        # use largest N peaks\n",
    "        if numPeaks[driveIdx] is not None and numPeaks[driveIdx] > 0:\n",
    "            selectedIndices = amps.argsort()[-numPeaks[driveIdx]:][::-1]\n",
    "            freqs = freqs[selectedIndices]\n",
    "            amps = amps[selectedIndices]\n",
    "            phases = phases[selectedIndices]\n",
    "            print(f\"Drive {driveName}: num peaks {len(selectedIndices)}\")\n",
    "        elif numPeaks[driveIdx] == 0:\n",
    "            freqs = np.array([])\n",
    "            amps = np.array([])\n",
    "            phases = np.array([])\n",
    "            print(f\"Drive {driveName}: empty\")\n",
    "        if selectedIndex[driveIdx] is not None and selectedIndex[driveIdx] >= 0:\n",
    "            freqs = freqs[selectedIndex[driveIdx]:selectedIndex[driveIdx] + 1]\n",
    "            amps = amps[selectedIndex[driveIdx]:selectedIndex[driveIdx] + 1]\n",
    "            phases = phases[selectedIndex[driveIdx]:selectedIndex[driveIdx] + 1]\n",
    "            print(f\"Drive {driveName}: selected index {len(freqs)}\")\n",
    "        elif includedIndices[driveIdx] is not None:\n",
    "            freqs = freqs[includedIndices[driveIdx]].flatten()\n",
    "            amps = amps[includedIndices[driveIdx]].flatten()\n",
    "            phases = phases[includedIndices[driveIdx]].flatten()\n",
    "            print(f\"Drive {driveName}: included indices {len(freqs)}\")\n",
    "\n",
    "        if addFreqs is not None and len(addFreqs) > 0: # and driveIdx == 0\n",
    "            for freq,amp,phase in addFreqs:\n",
    "                freqs = np.append(freqs, freq)\n",
    "                amps = np.append(amps, amp)\n",
    "                phases = np.append(phases, phase)\n",
    "        envelope.params[\"freqs\"] = Qty(value=freqs, min_val=0.95 * freqs, max_val=1.05 * freqs, unit=\"Hz 2pi\")\n",
    "        envelope.params[\"amps\"] = Qty(value=amps, min_val=1e-2 * amps, max_val=1e2 * amps, unit=\"V\")\n",
    "        envelope.params[\"phases\"] = Qty(value=phases, min_val=-np.pi * np.ones_like(phases),\n",
    "                                        max_val=np.pi * np.ones_like(phases), unit=\"rad\")\n",
    "\n",
    "        if len(freqs) > 0:\n",
    "            print(f\"frequencies {driveName}: {freqs[0]:e} {freqs[-1]:e} {len(freqs)}\")\n",
    "    return stored_params\n",
    "\n",
    "\n",
    "def createSpectralRange(limits: Tuple[float, float], num: int) -> Tuple[Dict, Dict, Dict]:\n",
    "    freqs = np.linspace(limits[0], limits[1], num)\n",
    "    selectedFreqsMap = {\"d1\": freqs, \"d2\": freqs}\n",
    "    selectedAmpsMap = {\"d1\": np.ones_like(freqs) * 1e-4, \"d2\": np.ones_like(freqs) * 1e-4}\n",
    "    selectedPhasesMap = {\"d1\": np.random.random(len(freqs)) * (2 * np.pi) - np.pi,\n",
    "                         \"d2\": np.random.random(len(freqs)) * (2 * np.pi) - np.pi}\n",
    "    return selectedFreqsMap, selectedAmpsMap, selectedPhasesMap\n",
    "\n",
    "\n",
    "def createPeaks(frequencies: np.array) -> Tuple[Dict, Dict, Dict]:\n",
    "    selectedFreqsMap = {\"d1\": frequencies, \"d2\": frequencies}\n",
    "    #selectedAmpsMap = {\"d1\": np.ones_like(frequencies) * 0.02, \"d2\": np.ones_like(frequencies) * 1e-8}\n",
    "    selectedAmpsMap = {\"d1\": np.array([0.015, 0.02, 0.007, 0.005]), \"d2\": np.ones_like(frequencies) * 1e-8}\n",
    "    #selectedPhasesMap = {\"d1\": np.random.random(len(frequencies)) * (2 * np.pi) - np.pi,\n",
    "    #                     \"d2\": np.random.random(len(frequencies)) * (2 * np.pi) - np.pi}\n",
    "    selectedPhasesMap = {\"d1\": np.ones_like(frequencies) * 1e-6, \"d2\": np.ones_like(frequencies) * 1e-6}\n",
    "    return selectedFreqsMap, selectedAmpsMap, selectedPhasesMap\n",
    "\n",
    "\n",
    "#stored_params = getConfigurationFromFile(INPUT_FILE, spectralRange=SPECTRAL_RANGE, numPeaks=NUM_PEAKS,\n",
    "#                                         selectedIndex=SELECTED_INDEX, includedIndices=INCLUDED_INDICES)\n",
    "''', addFreqs=[\n",
    "        (3.9442e9, 0.01, 0.0),  #|1,1>|1,0> -> |1,1>|1,1>\n",
    "    ])\n",
    "'''\n",
    "#selectedFreqsMap, selectedAmpsMap, selectedPhasesMap = getFourierBasisFromSignal(INPUT_FILE)\n",
    "#selectedFreqsMap, selectedAmpsMap, selectedPhasesMap = createSpectralRange(SPECTRAL_RANGE, 5000)\n",
    "frequenciesISWAP = [\n",
    "    501597035 + 1e6, #0,1 - 1,0\n",
    "    998832373, #0,3 - 1,2\n",
    "    432410922, #2,3 - 3,2\n",
    "    124400789, #3,0 - 2,1\n",
    "]\n",
    "frequenciesCNOT = [\n",
    "    4496278937.271106,  # 1,0 - 1,1\n",
    "    4000155450.169649,  #1,2 - 1,3\n",
    "    4528683390.390869,  #3,0 - 3,1\n",
    "    3944089976.6960983  #3,2 - 3,3\n",
    "]\n",
    "selectedFreqsMap, selectedAmpsMap, selectedPhasesMap = createPeaks(np.array(frequenciesCNOT))\n",
    "#selectedFreqsMap, selectedAmpsMap, selectedPhasesMap  = createPeaks(directTransitions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "generator = createGenerator(drives, sim_res=sim_res, awg_res=awg_res, highpass_cutoff_freq=-1, lowpass_cutoff_freq=-1, useWindow=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Envelopes and carriers\n",
    "#carrier_freqs = [1e-8, 1e-8]\n",
    "carrier_freqs = [1e-5, 1e-5]\n",
    "carrier_framechange = [0.00, 0.00]\n",
    "pulse_t_final = [t_final, t_final]\n",
    "pulse_sigmas = [t_final/5, t_final/5]\n",
    "pulse_amps = [1.0, 1.0]\n",
    "pulse_deltas = [0, 0]\n",
    "pulse_xy_angles = [0.0, 0.0]\n",
    "pulse_freq_offsets = [0.0, 0.0]\n",
    "\n",
    "envelopes = []\n",
    "envelopesForDrive = {d.name: [] for d in drives}\n",
    "carriers = []\n",
    "carriersForDrive = {d.name: [] for d in drives}\n",
    "\n",
    "#selectedFreqsMap, selectedAmpsMap, selectedPhasesMap = getFourierBasisFromModel(transitions)\n",
    "#stored_params = getConfigurationFromFile(\"./optimised_params/10freqsvariable_from15_CZ.json\", spectralRange=(3.5e9, 5.5e9), numPeaks=10)\n",
    "#selectedFreqsMap, selectedAmpsMap, selectedPhasesMap = getFourierBasisFromSignal(INPUT_FILE)\n",
    "#selectedFreqs = np.array(np.abs(directTransitions))\n",
    "#selectedAmps = np.ones_like(directTransitions) * 0.1\n",
    "#selectedFreqs = np.array([1e9])\n",
    "#selectedAmps = 0.1 * np.ones_like(selectedFreqs)\n",
    "#selectedPhases = np.ones_like(selectedFreqs)\n",
    "#print(selectedFreqs)\n",
    "for idx in [0, 1]:\n",
    "    #N = len(selectedFreqsMap[drives[idx].name])\n",
    "    selectedFreqs = selectedFreqsMap[drives[idx].name]#.get_value()\n",
    "    selectedAmps = selectedAmpsMap[drives[idx].name]#.get_value()\n",
    "    selectedPhases = selectedPhasesMap[drives[idx].name]#.get_value()\n",
    "    N = len(selectedFreqs)\n",
    "    #ampFactor = [4.0 / N * 1e-9] * 2\n",
    "    #print(f\"drive{idx}: \", selectedPeaks, ampFactor * selectedAmps)\n",
    "\n",
    "    env = createSinePulse(\n",
    "        frequencies=selectedFreqs,\n",
    "        amplitudes=selectedAmps,\n",
    "        phases=selectedPhases,\n",
    "        t_final=pulse_t_final[idx],\n",
    "        amp=pulse_amps[idx],\n",
    "        delta=pulse_deltas[idx],\n",
    "        xy_angle=pulse_xy_angles[idx],\n",
    "        freq_off=pulse_freq_offsets[idx],\n",
    "        useDrag=useDRAG\n",
    "    )\n",
    "    '''\n",
    "    env = createGaussianPulse(\n",
    "        t_final=pulse_t_final[idx],\n",
    "        sigma=pulse_t_final[idx] / 300.0,\n",
    "        amp=pulse_amps[idx],\n",
    "        delta=pulse_deltas[idx],\n",
    "        xy_angle=pulse_xy_angles[idx],\n",
    "        freq_off=pulse_freq_offsets[idx],\n",
    "        useDrag=useDRAG\n",
    "    )\n",
    "    '''\n",
    "    #env = scaleGaussianEnvelope(env, 2.0)\n",
    "    #env = createNoDriveEnvelope(t_final)\n",
    "    if usePWC:\n",
    "        env = convertToPWC(env, numPWCPieces)\n",
    "    env.name = f\"envelope_{drives[idx].name}\"\n",
    "    #env.params[\"amp\"] = scaleQuantity(env.params[\"amp\"], 0.5)\n",
    "    envelopes.append(env)\n",
    "    envelopesForDrive[drives[idx].name].append(env)\n",
    "\n",
    "    carrier_parameters = {\n",
    "        \"freq\": Qty(value=carrier_freqs[idx], min_val=0.98 * carrier_freqs[idx],\n",
    "                    max_val=1.02 * carrier_freqs[idx], unit=\"Hz 2pi\"),\n",
    "        \"framechange\": Qty(value=carrier_framechange[idx], min_val=-np.pi, max_val=3 * np.pi, unit=\"rad\"),\n",
    "    }\n",
    "    carrier = pulse.Carrier(\n",
    "        name=f\"carrier_{drives[idx].name}\",\n",
    "        desc=\"Frequency of the local oscillator\",\n",
    "        params=carrier_parameters,\n",
    "    )\n",
    "    carriers.append(carrier)\n",
    "    carriersForDrive[drives[idx].name].append(carrier)\n",
    "\n",
    "for idx in []:\n",
    "    driveName = drives[idx].name\n",
    "    stored_params_d = stored_params[\"drive_channels\"][driveName]\n",
    "    env: pulse.Envelope = copy.deepcopy(stored_params_d[f\"envelope_{driveName}\"])\n",
    "    if useDRAG and not isinstance(env, EnvelopeDrag):\n",
    "        print(\"Converting to DRAG\")\n",
    "        env = convertToDRAG(env)\n",
    "    elif not useDRAG and isinstance(env, EnvelopeDrag):\n",
    "        print(\"Converting from DRAG\")\n",
    "        env = convertFromDRAG(env)\n",
    "    #if env.params[\"t_final\"].get_value() != t_final:\n",
    "    #    env.params[\"amp\"] = scaleQuantity(env.params[\"amp\"], env.params[\"t_final\"].get_value() / t_final)\n",
    "    #    print(\"Signal scaled by \", env.params[\"t_final\"].get_value() / t_final)\n",
    "    #env.params[\"amp\"] = scaleQuantity(env.params[\"amp\"], 0.6)\n",
    "    env.params[\"t_final\"] = Qty(value=t_final, min_val=0.5*t_final, max_val=1.5*t_final, unit=\"s\")\n",
    "    if useDRAG and FORCE_DELTA:\n",
    "        env.params[\"delta\"] = Quantity(value=FORCE_DELTA, min_val=-5, max_val=5, unit=\"\")\n",
    "    if FORCE_FREQ_OFFSET:\n",
    "        env.params[\"freq_offset\"] = Qty(\n",
    "            value=pulse_freq_offsets[idx],\n",
    "            min_val=min(0.8 * pulse_freq_offsets[idx], 1.2 * pulse_freq_offsets[idx]) if pulse_freq_offsets[idx] != 0 else -1,\n",
    "            max_val=max(0.8 * pulse_freq_offsets[idx], 1.2 * pulse_freq_offsets[idx]) if pulse_freq_offsets[idx] != 0 else 1,\n",
    "            unit=\"Hz 2pi\",\n",
    "        )\n",
    "    if FORCE_XY_ANGLE:\n",
    "        env.params[\"xy_angle\"] = Qty(value=pulse_xy_angles[idx], min_val=-1.5 * np.pi, max_val=2.5 * np.pi, unit=\"rad\")\n",
    "    envelopes.append(env)\n",
    "    envelopesForDrive[driveName].append(env)\n",
    "\n",
    "    #shift = df if dstIdx == 0 else -df\n",
    "    carrier = copy.deepcopy(stored_params_d[f\"carrier_{driveName}\"])\n",
    "    carrier.name = f\"carrier_{driveName}\"\n",
    "    carriers.append(carrier)\n",
    "    carriersForDrive[driveName].append(carrier)\n",
    "\n",
    "#print(\"carrier: \", [[carrier.params[\"freq\"] for carrier in carriers] for carriers in carriersForDrive.values()])\n",
    "print(\"amp: \", [[env.params[\"amp\"] for env in envelopes] for envelopes in envelopesForDrive.values()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "printMatrix(IDEAL_GATE, level_labels, \"ideal_gate\", output)\n",
    "\n",
    "gate = gates.Instruction(\n",
    "    name=IDEAL_GATE_NAME,\n",
    "    #name=\"unity\",\n",
    "    targets=[0, 1],\n",
    "    t_start=0.0,\n",
    "    t_end=t_final,\n",
    "    channels=[d.name for d in drives],\n",
    "    ideal=IDEAL_GATE,\n",
    ")\n",
    "for drive in drives:\n",
    "    for env in envelopesForDrive[drive.name]:\n",
    "        gate.add_component(copy.deepcopy(env), drive.name)\n",
    "    for carrier in carriersForDrive[drive.name]:\n",
    "        gate.add_component(copy.deepcopy(carrier), drive.name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up the experiment\n",
    "parameter_map = PMap(instructions=[gate], model=model, generator=generator)\n",
    "exp = Exp(pmap=parameter_map, sim_res=sim_res)\n",
    "exp.set_opt_gates([gate.get_key()])\n",
    "\n",
    "unitaries = exp.compute_propagators()\n",
    "printPropagator(exp, gate, level_labels_with_leakage, output)\n",
    "#printAllSignals(exp, qubits[0], output, directory=\"devices_before\")\n",
    "#printAllSignals(exp, qubits[1], output, directory=\"devices_before\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtain all energies and transitions\n",
    "#stateEnergies = getEnergiesFromFile('./optimised_params/fourier basis 5 levels/level_energies.npy', level_labels_short)\n",
    "stateEnergies = getEnergiesFromModel(exp, gate, level_labels_short)\n",
    "\n",
    "transitions = calculateTransitions(stateEnergies)\n",
    "#for t in transitions:\n",
    "#    print(t)\n",
    "\n",
    "#directTransitions = np.array([np.abs(stateEnergies[i + 1][0] - stateEnergies[i][0]) for i in range(0, len(stateEnergies) - 1, 1)])\n",
    "#directTransitions = []\n",
    "#for i in range(0, len(stateEnergies)-1, 1):\n",
    "#    diff = stateEnergies[i+1][0] - stateEnergies[i][0]\n",
    "#    directTransitions.append(diff)\n",
    "#print(directTransitions)\n",
    "\n",
    "printSignal(exp, qubits, gate, output=output, states=transitions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find all energy eigenvalues of the full Hamiltonian calculated from the propagator over short times\n",
    "'''\n",
    "U = unitaries[gate.get_key()].numpy()\n",
    "interval = 1e-12\n",
    "tau = t_final / interval\n",
    "U = np.float_power(U, 1.0 / tau)\n",
    "diag = np.diagonal(U)\n",
    "#print(diag)\n",
    "energies = -np.angle(diag) / (2 * np.pi * interval)\n",
    "print(energies)\n",
    "'''\n",
    "'''\n",
    "# all energy levels with labels\n",
    "stateEnergies = zip(energies, level_labels_short)\n",
    "\n",
    "# all energy transitions\n",
    "items = sorted(stateEnergies, key=lambda x: x[0])\n",
    "transitions = []\n",
    "for i in range(len(items)):\n",
    "    for j in range(len(items)):\n",
    "        if i != j:\n",
    "            E = items[j][0] - items[i][0]\n",
    "            if E > 0:\n",
    "                transitions.append((E, items[i][1] + \" - \" + items[j][1]))\n",
    "\n",
    "transitions.sort(key=lambda x: x[0])\n",
    "#for t in transitions:\n",
    "#    print(t)\n",
    "\n",
    "#directTransitions = np.array([np.abs(stateEnergies[i + 1][0] - stateEnergies[i][0]) for i in range(0, len(stateEnergies) - 1, 1)])\n",
    "#directTransitions = []\n",
    "#for i in range(0, len(stateEnergies)-1, 1):\n",
    "#    diff = stateEnergies[i+1][0] - stateEnergies[i][0]\n",
    "#    directTransitions.append(diff)\n",
    "#print(directTransitions)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# Read the Stark-shifted energies from a file\n",
    "energies = np.load('/home/user/eigenvalues.npy')\n",
    "\n",
    "# Combine energies with state labels\n",
    "stateEnergies = zip(energies, level_labels_short)\n",
    "for energy,state in zip(energies, level_labels_short):\n",
    "    print(state, energy)\n",
    "\n",
    "# Compute all resonance energies\n",
    "items = sorted(stateEnergies, key=lambda x: x[0])\n",
    "transitions = []\n",
    "for i in range(len(items)):\n",
    "    for j in range(len(items)):\n",
    "        if i != j:\n",
    "            E = items[j][0] - items[i][0]\n",
    "            if E > 0:\n",
    "                transitions.append((E, items[i][1] + \" - \" + items[j][1]))\n",
    "\n",
    "transitions.sort(key=lambda x: x[0])\n",
    "for t in transitions:\n",
    "    print(t)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify the initial state\n",
    "psi_init = [[0] * model.tot_dim]\n",
    "for i in entanglementInitStateFull:\n",
    "    psi_init[0][i] = 1\n",
    "psi_init /= np.linalg.norm(psi_init)\n",
    "print(\"initial state: \", psi_init)\n",
    "init_state = tf.transpose(tf.constant(psi_init, tf.complex128))\n",
    "sequence = [gate.get_key()]\n",
    "\n",
    "#printTimeEvolution(exp, init_state, gate, level_labels, output)\n",
    "#printEntanglementEvolution(exp, gate, output)\n",
    "parameter_map.write_config(output.createFileName(\"parameter_map\", \"json\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify the parameters to be optimised and initialise the optimiser\n",
    "opt_map = []\n",
    "for drive in [drives[i] for i in OPTIMISABLE_DRIVES]:\n",
    "    for env in envelopesForDrive[drive.name]:\n",
    "        opt_map.append([(gate.get_key(), drive.name, env.name, \"amp\")])\n",
    "        #opt_map.append([(gate.get_key(), drive.name, env.name, \"freq_offset\")])\n",
    "        opt_map.append([(gate.get_key(), drive.name, env.name, \"xy_angle\")])\n",
    "        if useDRAG:\n",
    "            opt_map.append([(gate.get_key(), drive.name, env.name, \"delta\")])\n",
    "        if usePWC:\n",
    "            opt_map.append([(gate.get_key(), drive.name, env.name, \"inphase\")])\n",
    "            opt_map.append([(gate.get_key(), drive.name, env.name, \"quadrature\")])\n",
    "            #opt_map.append([(gate.get_key(), drive.name, env.name, \"t_bin_end\")])\n",
    "        else:\n",
    "            opt_map.append([(gate.get_key(), drive.name, env.name, \"amps\")])\n",
    "            if OPTIMISE_FREQUENCIES:\n",
    "                opt_map.append([(gate.get_key(), drive.name, env.name, \"freqs\")])\n",
    "            opt_map.append([(gate.get_key(), drive.name, env.name, \"phases\")])\n",
    "            if OPTIMISE_TFINAL:\n",
    "                opt_map.append([(gate.get_key(), drive.name, env.name, \"t_final\")])\n",
    "    #for carrier in carriersForDrive[drive.name]:\n",
    "    #    opt_map.append([(gate.get_key(), drive.name, carrier.name, \"freq\")])\n",
    "    #    #opt_map.append([(gate.get_key(), drive.name, carrier.name, \"framechange\")])\n",
    "parameter_map.set_opt_map(opt_map)\n",
    "parameter_map.print_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "infidelities = []\n",
    "\n",
    "for algorithm, params in selected_algorithms:\n",
    "    if algorithm == ALGORITHM_LBFGS:\n",
    "        infidelities = optimise(output, qubits, exp, algorithms.lbfgs, {\n",
    "            \"maxfun\": 50,\n",
    "            \"ftol\": 1e-5,\n",
    "            **params\n",
    "        }, gate)\n",
    "    elif algorithm == ALGORITHM_LBFGS_GRAD_FREE:\n",
    "        infidelities = optimise(output, qubits, exp, algorithms.lbfgs_grad_free, {\n",
    "            \"maxfun\": 1000,\n",
    "            \"gtol\": 1e-4,\n",
    "            \"ftol\": 1e-4,\n",
    "            **params\n",
    "        }, gate)\n",
    "    elif algorithm == ALGORITHM_CMAES:\n",
    "        infidelities = optimise(output, qubits, exp, algorithms.cmaes, {\n",
    "            \"popsize\": 15,\n",
    "            \"spread\": 0.02,\n",
    "            \"maxfevals\": 2000,\n",
    "            \"init_point\": \"True\",\n",
    "            \"stop_at_sigma\": 1e-3,\n",
    "            \"stop_at_convergence\": 20,\n",
    "            **params\n",
    "        }, gate)\n",
    "    elif algorithm == ALGORITHM_GCMAES:\n",
    "        infidelities = optimise(output, qubits, exp, algorithms.gcmaes, {\n",
    "            \"cmaes\": {\"popsize\": 12, \"spread\": 0.05, \"maxfevals\": 20,\n",
    "                      \"init_point\": \"True\", \"stop_at_sigma\": 1e-4, \"stop_at_convergence\": 20, **params[\"cmaes\"]},\n",
    "            \"lbfgs\": {\"maxfun\": 500, \"ftol\": 1e-6, **params[\"lbfgs\"]}\n",
    "        }, gate)\n",
    "    else:\n",
    "        print(\"Unknown algorithm: \", algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "output = DataOutput(output_dir, file_suffix='after')\n",
    "plotData(np.arange(len(infidelities)), infidelities, xlabel=\"Step\",\n",
    "         ylabel=\"Infidelity\", filename=output.createFileName(\"convergence\", \"svg\"))\n",
    "printSignal(exp, qubits, gate, output=output, states=transitions)\n",
    "#printAllSignals(exp, qubits, output, directory=\"devices_after\")\n",
    "printPropagator(exp, gate, level_labels_with_leakage, output, savePartials=False)\n",
    "#printTimeEvolution(exp, init_state, gate, level_labels, output)\n",
    "#printEntanglementEvolution(exp, gate, output)\n",
    "parameter_map.write_config(output.createFileName(\"parameter_map\", \"json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}